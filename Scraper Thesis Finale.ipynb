{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e61be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen,Request\n",
    "import pandas as pd\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8722d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squad_scraper (req):\n",
    "    req=Request(req, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    time.sleep(5)\n",
    "    with urlopen(req) as fp:\n",
    "        soup=BeautifulSoup(fp,\"html.parser\")\n",
    "\n",
    "    attr=[\"all_stats_standard\",\"all_stats_shooting\", \"all_stats_passing\",\"all_stats_passing_types\"\n",
    "              ,\"all_stats_gca\",\"all_stats_defense\", \"all_stats_possession\",\"all_stats_playing_time\",\"all_stats_misc\"]\n",
    "    \n",
    "    source=[]\n",
    "    stats=[]\n",
    "    to_app=[]\n",
    "    totale=[]\n",
    "    lista=[]    \n",
    "    source = soup.find(\"body\").find(\"div\", id=\"wrap\").find(\"div\", id=\"content\").find_all(\"div\",recursive=False)\n",
    "    for element in source:\n",
    "            if (element.get('id') in attr):\n",
    "                stats=element.find(\"table\").find(\"tbody\").find_all(\"tr\",recursive=False)\n",
    "                naz=element.find(\"table\").find(\"tbody\").find_all(\"tr\",recursive=False)\n",
    "                lista=[]\n",
    "                for row in stats:\n",
    "                    if (row.find(\"td\",attrs={\"data-stat\": \"position\"}).string==\"FW\" or\n",
    "                       row.find(\"td\",attrs={\"data-stat\": \"position\"}).string==\"FW,MF\" or\n",
    "                       row.find(\"td\",attrs={\"data-stat\": \"position\"}).string==\"MF,FW\"):\n",
    "                        to_app=[]\n",
    "                        to_app.append(row.find(\"th\").string)\n",
    "                        stats=row.find_all(\"td\")\n",
    "                        for i, dato in enumerate(stats):\n",
    "                            if i == 0:\n",
    "                                td_element= row.find('td', attrs={'data-stat': 'nationality'})\n",
    "                                span_element = td_element.find('a').find('span')\n",
    "                                naz = span_element.contents[-1].strip()                                \n",
    "                                to_app.append(naz)\n",
    "                                continue\n",
    "                                \n",
    "                            to_app.append(dato.string)\n",
    "    \n",
    "                            # Verifica se Ã¨ la penultima iterazione\n",
    "                            if i == len(stats) - 2:\n",
    "                                break\n",
    "                        lista.append(to_app)\n",
    "\n",
    "                df = pd.DataFrame(lista)\n",
    "               \n",
    "                totale.append(df)\n",
    "    df_unificato = totale[0]\n",
    "    for i in range(1,len(totale)):\n",
    "        #print(totale[i])\n",
    "        df_unificato = pd.concat([df_unificato, totale[i].iloc[:, 5:]], axis=1)\n",
    "    df_unificato[\"League\"]=campionato\n",
    "    df_unificato[\"Team\"]=team_\n",
    "    df_unificato[\"Ranking_2022/23\"]=pos\n",
    "    return df_unificato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7229ead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "req=Request(\"https://fbref.com/en/comps/9/2022-2023/2022-2023-Premier-League-Stats\", headers={'User-Agent': 'Mozilla/5.0'})\n",
    "with urlopen(req) as fp:\n",
    "    soup=BeautifulSoup(fp,\"html.parser\") \n",
    "\n",
    "source=[]\n",
    "stats=[]\n",
    "totale=[]\n",
    "to_app=[]\n",
    "\n",
    "source = soup.find(\"body\").find(\"div\", id=\"wrap\").find(\"div\", id=\"content\").find_all(\"div\",recursive=False)\n",
    "table=source[2].find_all(\"div\")[7].find(\"table\").find(\"tbody\").find_all(\"tr\",recursive=False)\n",
    "campionato=\"Premier_League\"\n",
    "squadre=[]\n",
    "team=[]\n",
    "lista_db=[]\n",
    "for element in table:\n",
    "    squadre.append(element.find(\"a\").get(\"href\"))\n",
    "    team.append(element.find(\"a\").string)\n",
    "    \n",
    "i=0\n",
    "for element in squadre:\n",
    "    pos=i+1\n",
    "    team_=team[i]\n",
    "    link =\"https://fbref.com\" + element\n",
    "    lista_db.append(squad_scraper(link))\n",
    "    i=i+1\n",
    "df_unificato=lista_db[0]\n",
    "for i in range(1,len(lista_db)):\n",
    "        df_unificato = pd.concat([df_unificato, lista_db[i]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e828889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unificato=df_unificato.reset_index(drop=True) \n",
    "df_unificato.to_csv(\"C:/Users/danie/OneDrive/Desktop/Tesi Data Science/Singoli Campionati/Premier_League.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d508af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "req=Request(\"https://fbref.com/en/comps/20/2022-2023/2022-2023-Bundesliga-Stats\", headers={'User-Agent': 'Mozilla/5.0'})\n",
    "with urlopen(req) as fp:\n",
    "    soup=BeautifulSoup(fp,\"html.parser\") \n",
    "\n",
    "source=[]\n",
    "stats=[]\n",
    "totale=[]\n",
    "to_app=[]\n",
    "\n",
    "source = soup.find(\"body\").find(\"div\", id=\"wrap\").find(\"div\", id=\"content\").find_all(\"div\",recursive=False)\n",
    "table=source[2].find_all(\"div\")[7].find(\"table\").find(\"tbody\").find_all(\"tr\",recursive=False)\n",
    "campionato=\"Bundesliga\"\n",
    "squadre=[]\n",
    "team=[]\n",
    "lista_db=[]\n",
    "for element in table:\n",
    "    squadre.append(element.find(\"a\").get(\"href\"))\n",
    "    team.append(element.find(\"a\").string)\n",
    "    \n",
    "i=0\n",
    "for element in squadre:\n",
    "    pos=i+1\n",
    "    team_=team[i]\n",
    "    link =\"https://fbref.com\" + element\n",
    "    lista_db.append(squad_scraper(link))\n",
    "    i=i+1\n",
    "df_unificato=lista_db[0]\n",
    "for i in range(1,len(lista_db)):\n",
    "        df_unificato = pd.concat([df_unificato, lista_db[i]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "909c5e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unificato=df_unificato.reset_index(drop=True) \n",
    "df_unificato.to_csv(\"C:/Users/danie/OneDrive/Desktop/Tesi Data Science/Singoli Campionati/Bundesliga.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79a9debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "req=Request(\"https://fbref.com/en/comps/12/2022-2023/2022-2023-La-Liga-Stats\", headers={'User-Agent': 'Mozilla/5.0'})\n",
    "with urlopen(req) as fp:\n",
    "    soup=BeautifulSoup(fp,\"html.parser\") \n",
    "\n",
    "source=[]\n",
    "stats=[]\n",
    "totale=[]\n",
    "to_app=[]\n",
    "\n",
    "source = soup.find(\"body\").find(\"div\", id=\"wrap\").find(\"div\", id=\"content\").find_all(\"div\",recursive=False)\n",
    "table=source[2].find_all(\"div\")[7].find(\"table\").find(\"tbody\").find_all(\"tr\",recursive=False)\n",
    "campionato=\"La_Liga\"\n",
    "squadre=[]\n",
    "team=[]\n",
    "lista_db=[]\n",
    "for element in table:\n",
    "    squadre.append(element.find(\"a\").get(\"href\"))\n",
    "    team.append(element.find(\"a\").string)\n",
    "    \n",
    "i=0\n",
    "for element in squadre:\n",
    "    pos=i+1\n",
    "    team_=team[i]\n",
    "    link =\"https://fbref.com\" + element\n",
    "    lista_db.append(squad_scraper(link))\n",
    "    i=i+1\n",
    "df_unificato=lista_db[0]\n",
    "for i in range(1,len(lista_db)):\n",
    "        df_unificato = pd.concat([df_unificato, lista_db[i]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ce2596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unificato=df_unificato.reset_index(drop=True) \n",
    "df_unificato.to_csv(\"C:/Users/danie/OneDrive/Desktop/Tesi Data Science/Singoli Campionati/La_Liga.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6a68017",
   "metadata": {},
   "outputs": [],
   "source": [
    "req=Request(\"https://fbref.com/en/comps/13/2022-2023/2022-2023-Ligue-1-Stats\", headers={'User-Agent': 'Mozilla/5.0'})\n",
    "with urlopen(req) as fp:\n",
    "    soup=BeautifulSoup(fp,\"html.parser\") \n",
    "\n",
    "source=[]\n",
    "stats=[]\n",
    "totale=[]\n",
    "to_app=[]\n",
    "\n",
    "source = soup.find(\"body\").find(\"div\", id=\"wrap\").find(\"div\", id=\"content\").find_all(\"div\",recursive=False)\n",
    "table=source[2].find_all(\"div\")[7].find(\"table\").find(\"tbody\").find_all(\"tr\",recursive=False)\n",
    "campionato=\"Ligue_1\"\n",
    "squadre=[]\n",
    "team=[]\n",
    "lista_db=[]\n",
    "for element in table:\n",
    "    squadre.append(element.find(\"a\").get(\"href\"))\n",
    "    team.append(element.find(\"a\").string)\n",
    "    \n",
    "i=0\n",
    "for element in squadre:\n",
    "    pos=i+1\n",
    "    team_=team[i]\n",
    "    link =\"https://fbref.com\" + element\n",
    "    lista_db.append(squad_scraper(link))\n",
    "    i=i+1\n",
    "df_unificato=lista_db[0]\n",
    "for i in range(1,len(lista_db)):\n",
    "        df_unificato = pd.concat([df_unificato, lista_db[i]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cc45c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unificato=df_unificato.reset_index(drop=True) \n",
    "df_unificato.to_csv(\"C:/Users/danie/OneDrive/Desktop/Tesi Data Science/Singoli Campionati/Ligue_1.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "091b6867",
   "metadata": {},
   "outputs": [],
   "source": [
    "req=Request(\"https://fbref.com/en/comps/11/2022-2023/2022-2023-Serie-A-Stats\", headers={'User-Agent': 'Mozilla/5.0'})\n",
    "with urlopen(req) as fp:\n",
    "    soup=BeautifulSoup(fp,\"html.parser\") \n",
    "\n",
    "source=[]\n",
    "stats=[]\n",
    "totale=[]\n",
    "to_app=[]\n",
    "\n",
    "source = soup.find(\"body\").find(\"div\", id=\"wrap\").find(\"div\", id=\"content\").find_all(\"div\",recursive=False)\n",
    "table=source[2].find_all(\"div\")[7].find(\"table\").find(\"tbody\").find_all(\"tr\",recursive=False)\n",
    "campionato=\"Serie_A\"\n",
    "squadre=[]\n",
    "team=[]\n",
    "lista_db=[]\n",
    "for element in table:\n",
    "    squadre.append(element.find(\"a\").get(\"href\"))\n",
    "    team.append(element.find(\"a\").string)\n",
    "    \n",
    "i=0\n",
    "for element in squadre:\n",
    "    pos=i+1\n",
    "    team_=team[i]\n",
    "    link =\"https://fbref.com\" + element\n",
    "    lista_db.append(squad_scraper(link))\n",
    "    i=i+1\n",
    "df_unificato=lista_db[0]\n",
    "for i in range(1,len(lista_db)):\n",
    "        df_unificato = pd.concat([df_unificato, lista_db[i]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9f8ffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unificato=df_unificato.reset_index(drop=True) \n",
    "df_unificato.to_csv(\"C:/Users/danie/OneDrive/Desktop/Tesi Data Science/Singoli Campionati/Serie_A.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83966342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
